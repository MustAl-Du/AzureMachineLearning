{
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Train and register an ONNX model with AutoML\r\n",
        "---\r\n",
        "---\r\n",
        "\r\n",
        "## Contents\r\n",
        "1. [Introduction](#Introduction)\r\n",
        "2. [Setup](#Setup)\r\n",
        "3. [Data](#Data)\r\n",
        "4. [Train](#Train)\r\n",
        "5. [Synape Link to Azure ML](#SynapeLinktoAzureML)\r\n",
        "6. [Confusion Matrix](#ConfusionMatrix)\r\n",
        "7. [Model Explaination](#ModelExplaination)\r\n",
        "\r\n",
        "---\r\n",
        "\r\n",
        "## Introduction\r\n",
        "Azure Machine Learning provides capabilities to control all aspects of model training and deployment directly from a notebook using the AML Python SDK.  In this notebook we will\r\n",
        "* connect to our AML Workspace\r\n",
        "* create an experiment that contains all runs\r\n",
        "* Run AutoML to find the best model \r\n",
        "* Save the AutoML model as ONNX\r\n",
        "* Register the ONNX Model \r\n",
        "\r\n",
        "In the end the ONNX Model will be accessible through Synapse Link to Azure Machine Learning"
      ],
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "---\r\n",
        "\r\n",
        "## Setup\r\n",
        "Create an Azure Machine Learning servcie in Azure, and launch the studio. \r\n",
        "\r\n",
        "Create a Workspace, a Compute Instance (VM) and a new Notebook running on that VM as a compute target.  \r\n",
        "\r\n",
        "This example was forked from https://github.com/Azure/MachineLearningNotebooks, and further developed to present an end-to-end example. \r\n",
        "\r\n",
        "For this notebook we need the Azure ML SDK and access to our workspace.  The following cell imports the SDK, checks the version, and accesses our already configured AzureML workspace. \r\n",
        "\r\n",
        "See more detail on [Git Integration](https://docs.microsoft.com/en-us/azure/machine-learning/concept-train-model-git-integration#:~:text=Azure%20Machine%20Learning%20provides%20a%20shared%20file%20system,work%20with%20Git%20via%20the%20Git%20CLI%20experience) if you need to upload this notebook in AML."
      ],
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import azureml.core\r\n",
        "from azureml.core import Experiment, Workspace\r\n",
        "\r\n",
        "# Check core SDK version number\r\n",
        "print(\"This notebook was created using version 1.0.2 of the Azure ML SDK\")\r\n",
        "print(\"You are currently using version\", azureml.core.VERSION, \"of the Azure ML SDK\")\r\n",
        "print(\"\")\r\n",
        "\r\n",
        "\r\n",
        "ws = Workspace.from_config()\r\n",
        "print('Workspace name: ' + ws.name, \r\n",
        "      'Azure region: ' + ws.location, \r\n",
        "      'Subscription id: ' + ws.subscription_id, \r\n",
        "      'Resource group: ' + ws.resource_group, sep='\\n')"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1623160368224
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "---\r\n",
        "\r\n",
        "## Data\r\n",
        "We will use the diabetes dataset for this experiement (https://aka.ms/diabetes-data). \r\n",
        "\r\n",
        "The dataset consists of 8 baseline variables for n=10000 diabetes patients: Pregnancies, PlasmaGlucose, DiastolicBloodPressure, TricepsThickness, SerumInsulin, BMI, DiabetesPedigree, and Age.\r\n",
        "\r\n",
        "The dataset has one dichotomous outcome variable: Diebetic."
      ],
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from azureml.core import Dataset\r\n",
        "import pandas as pd\r\n",
        "from sklearn.model_selection import train_test_split\r\n",
        "\r\n",
        "# load the diabetes dataset from the same folder where this notebook is located\r\n",
        "print(\"Loading Diabetes Data from the CSV file...\")\r\n",
        "dataset = pd.read_csv('./diabetes.csv')\r\n",
        "\r\n",
        "# Separate features and labels\r\n",
        "X, y = dataset[['Pregnancies','PlasmaGlucose','DiastolicBloodPressure','TricepsThickness','SerumInsulin','BMI','DiabetesPedigree','Age']].values, dataset['Diabetic'].values\r\n",
        "# Split data into training set and test set (80% Training and 20% Testing)\r\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.20, random_state=0)\r\n",
        "\r\n",
        "data = {\r\n",
        "    \"train\":{\"X\": X_train, \"y\": y_train},        \r\n",
        "    \"test\":{\"X\": X_test, \"y\": y_test}\r\n",
        "}\r\n",
        "\r\n",
        "print (\"Data contains\", len(data['train']['X']), \"training samples and\",len(data['test']['X']), \"test samples\")\r\n"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1623160384435
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "---\r\n",
        "## Train\r\n",
        "\r\n",
        "Let's use AutoML to train the dataset. There are two prerequisits for onnx:\r\n",
        "\r\n",
        "1- Use tablular dataset to point to the CSV file (https path required)\r\n",
        "\r\n",
        "2- Remote compute target will be required."
      ],
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# CSV URL required (public https URL)\r\n",
        "\r\n",
        "# The url for this AML Workspace below is not public and will not work. Hence will us the GitHub RAW URL\r\n",
        "# csv_path = 'https://ml.azure.com/fileexplorerAzNB?wsid=/subscriptions/61489282-e75d-4996-b2ef-3126311e55e6/resourcegroups/Ramsoft/workspaces/workspacers&tid=72f988bf-86f1-41af-91ab-2d7cd011db47&activeFilePath=Users/mualdurr/AzureMachineLearning/diabetescsv-automl-onnx-synapse/diabetes.csv'\r\n",
        "\r\n",
        "csv_path = 'https://raw.githubusercontent.com/MustAl-Du/AzureMachineLearning/main/diabetescsv-regression-aks-drift/diabetes.csv'\r\n",
        "csv_path\r\n"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1623160390313
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Current compute target name\r\n",
        "computetarget_name = 'computeinstancers'\r\n",
        "computetarget_name"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1623160392577
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Make the existing compute instance as the comptue target\r\n",
        "from azureml.core.compute import ComputeTarget, AmlCompute\r\n",
        "from azureml.core.compute_target import ComputeTargetException\r\n",
        "# Verify that cluster does not exist already\r\n",
        "try:\r\n",
        "    compute_target = ComputeTarget(workspace=ws, name=computetarget_name)\r\n",
        "    print('Found existing cluster, use it.')\r\n",
        "except ComputeTargetException:\r\n",
        "    compute_config = AmlCompute.provisioning_configuration(vm_size='STANDARD_D2_V2',\r\n",
        "                                                           max_nodes=6)\r\n",
        "    compute_target = ComputeTarget.create(ws, computetarget_name, compute_config)\r\n",
        "\r\n",
        "compute_target.wait_for_completion(show_output=True)"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1623160401169
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import logging\r\n",
        "from azureml.train.automl import AutoMLConfig\r\n",
        "from azureml.widgets import RunDetails\r\n",
        "\r\n",
        "dataset = Dataset.Tabular.from_delimited_files(csv_path)\r\n",
        "training_data, validation_data = dataset.random_split(percentage=0.8, seed=223)\r\n",
        "\r\n",
        "\r\n",
        "# Get an experiment object from Azure Machine Learning\r\n",
        "experiment = Experiment(workspace=ws, name=\"diabetes-automl-onnx\")\r\n",
        "\r\n",
        "# Create a run object in the experiment\r\n",
        "run =  experiment.start_logging()\r\n",
        "\r\n",
        "\r\n",
        "automl_settings = {\r\n",
        "    \"n_cross_validations\": 3,\r\n",
        "    \"primary_metric\": 'AUC_weighted',\r\n",
        "    \"experiment_timeout_minutes\": 17,\r\n",
        "    \"experiment_timeout_hours\": 0.25, # This is a time limit for testing purposes, remove it for real use cases, this will drastically limit ability to find the best model possible\r\n",
        "    \"verbosity\": logging.INFO,\r\n",
        "    \"enable_stack_ensemble\": False\r\n",
        "}\r\n",
        "\r\n",
        "automl_config = AutoMLConfig(task = 'classification',\r\n",
        "                             debug_log = 'automl_errors.log',\r\n",
        "                             compute_target=compute_target,\r\n",
        "                             enable_onnx_compatible_models=True, # must be explicitly declared for onnx\r\n",
        "                             blocked_models = ['KNN','LinearSVM'], # example of skipping a few algorithms\r\n",
        "                             training_data = training_data,\r\n",
        "                             label_column_name = 'Diabetic', # the output label \r\n",
        "                             **automl_settings\r\n",
        "                            )\r\n",
        "\r\n",
        "local_run = experiment.submit(automl_config, show_output = True)\r\n",
        "\r\n",
        "RunDetails(local_run).show()"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1623161801775
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Get the best fitted model\r\n",
        "best_run, fitted_model = local_run.get_output()\r\n",
        "fitted_model"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1622128289503
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Retrieve and save the ONNX format of the best fitted model\r\n",
        "from azureml.automl.runtime.onnx_convert import OnnxConverter\r\n",
        "\r\n",
        "best_run, onnx_mdl = local_run.get_output(return_onnx_model=True)\r\n",
        "onnx_filepath = \"./best_fitted_model.onnx\"\r\n",
        "OnnxConverter.save_onnx_model(onnx_mdl, onnx_fl_path)"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1622128383064
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Register the Model in AML for later reference in Synapse\r\n",
        "from azureml.core import Model\r\n",
        "\r\n",
        "model = Model.register(model_path = onnx_filepath,\r\n",
        "                       model_name = \"DiabeticONNXModel\",\r\n",
        "                       model_framework=Model.Framework.ONNX ,  \r\n",
        "                       tags = {\"onnx\":\"V0\"},\r\n",
        "                       description = \"DiabeticONNXModel\",\r\n",
        "                       workspace = ws)"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1622128388728
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Synape Link to Azure ML\r\n",
        "\r\n",
        "Create a Service Principal, add it to AML workspace: https://docs.microsoft.com/en-us/azure/synapse-analytics/machine-learning/quickstart-integrate-azure-machine-learning\r\n",
        "\r\n",
        "In Synapse Studio link to this AML: https://docs.microsoft.com/en-us/azure/synapse-analytics/machine-learning/tutorial-sql-pool-model-scoring-wizard. You could follow that example and modify to this diebetes dataset and onnx model. In essence, it does thse three steps:\r\n",
        "\r\n",
        "1- Upload the diebetes.csv file in Synapse primary storage account (or access it from AML storage after granting access rights)\r\n",
        "\r\n",
        "2- Create a table in Synapse Dedicated SQL Pool and populate it from teh csv file (see [CreateInsertDiabeticTable.sql](./CreateInsertDiabeticTable.sql))\r\n",
        "\r\n",
        "3- Right-click the table->Machine Leanring->Enrich with Exsiting model. Choose your Azure ML workspace and the registered ONNX Model.\r\n",
        "\r\n",
        "4- The Wizard would create a table to host the model, and a stored procedure to run the prediction. Follow this mapping between the Diabetic table and ONNX Model:\r\n",
        "<img src=\"./MappingModelColumns.PNG\">\r\n",
        "\r\n",
        "5- Execute the Stored Procedure [PredictDiabetic](./PredictDiabetic.sql) to see the predictions\r\n",
        "6- Y"
      ],
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Confusion Matrix \r\n",
        "\r\n",
        "Creating a confusion matrix"
      ],
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Create confusion matrix (dataset needs to be in dataframes)\r\n",
        "from sklearn.metrics import confusion_matrix\r\n",
        "import numpy as np\r\n",
        "import itertools\r\n",
        "from matplotlib import pyplot as plt\r\n",
        "\r\n",
        "\r\n",
        "# convert the test data to dataframe\r\n",
        "X_test_df = validation_data.drop_columns(columns=['Diabetic']).to_pandas_dataframe()\r\n",
        "y_test_df = validation_data.keep_columns(columns=['Diabetic'], validate=True).to_pandas_dataframe()\r\n",
        "# call the predict functions on the model\r\n",
        "y_pred = fitted_model.predict(X_test_df)\r\n",
        "y_pred\r\n",
        "\r\n",
        "\r\n",
        "\r\n",
        "cf =confusion_matrix(y_test_df.values,y_pred)\r\n",
        "plt.imshow(cf,cmap=plt.cm.Blues,interpolation='nearest')\r\n",
        "plt.colorbar()\r\n",
        "plt.title('Confusion Matrix')\r\n",
        "plt.xlabel('Predicted')\r\n",
        "plt.ylabel('Actual')\r\n",
        "class_labels = ['False','True']\r\n",
        "tick_marks = np.arange(len(class_labels))\r\n",
        "plt.xticks(tick_marks,class_labels)\r\n",
        "plt.yticks([-0.5,0,1,1.5],['','False','True',''])\r\n",
        "# plotting text value inside cells\r\n",
        "thresh = cf.max() / 2.\r\n",
        "for i,j in itertools.product(range(cf.shape[0]),range(cf.shape[1])):\r\n",
        "    plt.text(j,i,format(cf[i,j],'d'),horizontalalignment='center',color='white' if cf[i,j] >thresh else 'black')\r\n",
        "plt.show()"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1622129466970
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Model Explaination\r\n",
        "\r\n",
        "Creating Model Explaination"
      ],
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Run explaination\r\n",
        "from azureml.interpret import ExplanationClient\r\n",
        "\r\n",
        "client = ExplanationClient.from_run(best_run)\r\n",
        "engineered_explanations = client.download_model_explanation(raw=False)\r\n",
        "print(engineered_explanations.get_feature_importance_dict())\r\n",
        "print(\"You can visualize the engineered explanations under the 'Explanations (preview)' tab in the AutoML run at:-\\n\" + best_run.get_portal_url())"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1622129525063
        }
      }
    }
  ],
  "metadata": {
    "kernelspec": {
      "name": "python3-azureml",
      "language": "python",
      "display_name": "Python 3.6 - AzureML"
    },
    "language_info": {
      "name": "python",
      "version": "3.6.9",
      "mimetype": "text/x-python",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "pygments_lexer": "ipython3",
      "nbconvert_exporter": "python",
      "file_extension": ".py"
    },
    "kernel_info": {
      "name": "python3-azureml"
    },
    "nteract": {
      "version": "nteract-front-end@1.0.0"
    },
    "microsoft": {
      "host": {
        "AzureML": {
          "notebookHasBeenCompleted": true
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}